{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers accelerate torch huggingface_hub datasets nervaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa-TweetNER pipeline attempts (brd-sa-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out RoBERTa version trained with tweetner\n",
    "# tner/roberta-base-tweetner7-all\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "model_name = \"tner/roberta-base-tweetner7-all\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"Apple just launched the new iPhone, and Microsoft released a new version of Windows.\"\n",
    "\n",
    "entities = ner_pipeline(text)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entities = [{\"word\": entity[\"word\"], \"entity\": entity[\"entity\"]} for entity in entities]\n",
    "print(filtered_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing NER on Brand Sentiment Analysis data\n",
    "import pandas as pd\n",
    "df_brd_sa = pd.read_csv(\"./analysis_data/Brand Sentiment Analysis Dataset/Dataset - Train.csv\")\n",
    "df_brd_sa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying pre-processing function before model application from https://huggingface.co/tner/roberta-base-tweetner7-all\n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "\n",
    "extractor = URLExtract()\n",
    "\n",
    "def format_tweet(tweet):\n",
    "    # mask web urls\n",
    "    urls = extractor.find_urls(tweet)\n",
    "    for url in urls:\n",
    "        tweet = tweet.replace(url, \"{{URL}}\")\n",
    "    # format twitter account\n",
    "    tweet = re.sub(r\"\\b(\\s*)(@[\\S]+)\\b\", r'\\1{\\2@}', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brd_sa_sm = df_brd_sa[:100]\n",
    "\n",
    "df_brd_sa_sm.dropna()\n",
    "\n",
    "df_brd_sa_sm[\"tweet_text\"] = df_brd_sa_sm.apply(lambda x: format_tweet(str(x[\"tweet_text\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(txt):\n",
    "    entities = ner_pipeline(txt)\n",
    "    entities = [{\"word\": entity[\"word\"], \"entity\": entity[\"entity\"]} for entity in entities]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brd_sa[\"entities\"] = df_brd_sa.apply(lambda x: ner(str(x[\"tweet_text\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brd_sa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reslist = list(df_brd_sa[[\"tweet_text\", \"entities\"]].values)\n",
    "#print(reslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json allows entities-column to be stored in the CSV\n",
    "import json\n",
    "df_brd_sa[\"entities\"] = df_brd_sa[\"entities\"].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the df containing the prediction results as CSV to be used further\n",
    "df_brd_sa.to_csv(\"./data after NER.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading TweetNER7-data and applying roberta-tweetner-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading tweetner17 dataset from huggingface https://huggingface.co/datasets/tner/tweetner7\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"tner/tweetner7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_train = ds[\"train_all\"].to_pandas()\n",
    "tweetner7_test = ds[\"test_2021\"].to_pandas()\n",
    "tweetner7_test20 = ds[\"test_2020\"].to_pandas()\n",
    "tweetner7_train.dropna(inplace=True)\n",
    "tweetner7_test.dropna(inplace=True)\n",
    "tweetner7_test20.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_big = pd.concat([tweetner7_train, tweetner7_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweetner7_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the tags-column to a label-column to be comparable with the model-output\n",
    "entity_dict = {\n",
    "    0: \"B-corporation\",\n",
    "    1: \"B-creative_work\",\n",
    "    2: \"B-event\",\n",
    "    3: \"B-group\",\n",
    "    4: \"B-location\",\n",
    "    5: \"B-person\",\n",
    "    6: \"B-product\",\n",
    "    7: \"I-corporation\",\n",
    "    8: \"I-creative_work\",\n",
    "    9: \"I-event\",\n",
    "    10: \"I-group\",\n",
    "    11: \"I-location\",\n",
    "    12: \"I-person\",\n",
    "    13: \"I-product\",\n",
    "    14: \"O\"\n",
    "}\n",
    "\n",
    "label_list = list(entity_dict.values())\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "def tags_to_labels(col):\n",
    "    result = []\n",
    "    for i in col:\n",
    "        label = entity_dict[i]\n",
    "        result.append(label)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_test[\"true_labels\"] = tweetner7_test[\"tags\"].apply(tags_to_labels)\n",
    "tweetner7_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_train[\"ner_pipeline\"] = tweetner7_train.apply(lambda x: ner_pipeline(str(x[\"tokens\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example output of the pipeline\n",
    "#test_example = [{'entity': 'B-corporation', 'score': 0.5353071, 'index': 1, 'word': 'Apple', 'start': 0, 'end': 5},\n",
    "#{'entity': 'B-product', 'score': 0.656318, 'index': 6, 'word': 'ĠiPhone', 'start': 28, 'end': 34},\n",
    "#{'entity': 'B-corporation', 'score': 0.70640016, 'index': 9, 'word': 'ĠMicrosoft', 'start': 40, 'end': 49},\n",
    "#{'entity': 'B-product', 'score': 0.6205899, 'index': 15, 'word': 'ĠWindows', 'start': 76, 'end': 83}]\n",
    "\n",
    "# creating a function transforming the predicted labels to a list to be better comparable to the actual entity labels\n",
    "def output_to_labellist(row, output_col):\n",
    "    labellist = []\n",
    "    words_labels = {}\n",
    "\n",
    "    # adjust column-name depending on name of prediction-column\n",
    "    for dic in row[output_col]:\n",
    "        words_labels[dic[\"word\"]] = dic[\"entity\"]\n",
    "\n",
    "    for i in row[\"tokens\"]:\n",
    "        if i in words_labels.keys():\n",
    "            labellist.append(words_labels[i])\n",
    "        else:\n",
    "            labellist.append(\"O\")\n",
    "\n",
    "    return labellist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_train[\"predicted_labels\"] = tweetner7_train.apply(output_to_labellist, axis=1)\n",
    "tweetner7_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the package \"nervaluate\" to evaluate the performance\n",
    "from nervaluate import Evaluator\n",
    "\n",
    "true = tweetner7_train[\"true_labels\"].values.tolist()\n",
    "pred = tweetner7_train[\"predicted_labels\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"creative_work\", \"event\", \"group\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_tag[\"person\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting with function similar to llama-approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# add_prefix_space necessary fixes issue with prediction function\n",
    "roberta_tweetner_t = AutoTokenizer.from_pretrained(\"tner/roberta-base-tweetner7-all\", add_prefix_space=True)\n",
    "\n",
    "roberta_tweetner = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"tner/roberta-base-tweetner7-all\",\n",
    "    device_map=\"auto\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function explicitly handles numpy arrays, not needed for llama\n",
    "# (tweetner7-tokens are saved as such) and encodes immediately\n",
    "# function should work for all BERT-/RoBERTa-models\n",
    "import numpy as np\n",
    "\n",
    "def bert_pred(model, tokenizer, df, text_col, output_col):\n",
    "\n",
    "    model.to(model.device)\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        text = row[text_col]\n",
    "\n",
    "        if isinstance(text, np.ndarray):\n",
    "            if text.dtype.kind == 'U' or text.dtype.kind == 'S':  # if array contains strings\n",
    "                text_list = text.tolist()\n",
    "            else:\n",
    "                text_list = [str(x) for x in text]\n",
    "\n",
    "            encoded = tokenizer(text_list, is_split_into_words=True, return_tensors=\"pt\")\n",
    "        elif isinstance(text, str):\n",
    "            encoded = tokenizer(text, return_tensors=\"pt\")\n",
    "        elif isinstance(text, list):\n",
    "            encoded = tokenizer(text, is_split_into_words=True, return_tensors=\"pt\")\n",
    "        else:\n",
    "            encoded = tokenizer(str(text), return_tensors=\"pt\")\n",
    "\n",
    "        # moving encoded text to device\n",
    "        encoded = {k: v.to(model.device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)[0].cpu().tolist()\n",
    "\n",
    "            # mapping predictions back to original tokens for token classification\n",
    "            if isinstance(text, (list, np.ndarray)):\n",
    "                if isinstance(text, np.ndarray):\n",
    "                    word_ids = tokenizer(text.tolist(), is_split_into_words=True).word_ids()\n",
    "                else:\n",
    "                    word_ids = tokenizer(text, is_split_into_words=True).word_ids()\n",
    "\n",
    "                processed_preds = []\n",
    "                prev_word_id = None\n",
    "\n",
    "                for word_id, pred in zip(word_ids, preds):\n",
    "                    if word_id is None:\n",
    "                        continue\n",
    "                    elif word_id != prev_word_id:\n",
    "                        processed_preds.append(pred)\n",
    "                    prev_word_id = word_id\n",
    "\n",
    "                all_predictions.append(processed_preds)\n",
    "            else:\n",
    "                all_predictions.append(preds)\n",
    "\n",
    "    df[output_col] = all_predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(roberta_tweetner, roberta_tweetner_t, tweetner7_test, \"tokens\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_test[\"roberta_prediction_labels\"] = tweetner7_test[\"roberta_pred\"].apply(lambda x: [id_to_label[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "true = tweetner7_test[\"true_labels\"].values.tolist()\n",
    "pred = tweetner7_test[\"roberta_prediction_labels\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"creative_work\", \"event\", \"group\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "# function returns dictionary containing precision, recall and f1-score\n",
    "# should only be used for comparing columns with numeric tags, not string-labels\n",
    "def evaluate_ner_predictions(df, true_col, pred_col):\n",
    "    y_true_flat = []\n",
    "    y_pred_flat = []\n",
    "\n",
    "    for true_seq, pred_seq in zip(df[true_col], df[pred_col]):\n",
    "       # skipping padding/special tokens (marked as -100 in ground truth)\n",
    "       for true_label, pred_label in zip(true_seq, pred_seq):\n",
    "            if true_label != -100:\n",
    "               y_true_flat.append(true_label)\n",
    "               y_pred_flat.append(pred_label)\n",
    "\n",
    "    precision = precision_score(y_true_flat, y_pred_flat, average='weighted')\n",
    "    recall = recall_score(y_true_flat, y_pred_flat, average='weighted', zero_division=0)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(classification_report(y_true_flat, y_pred_flat))\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(tweetner7_test, \"tags\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing RoBERTa-tweetner7 with WNUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_wnut = pd.read_csv(\"./wnut_complete_processed.csv\")\n",
    "df_wnut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "for col in [\"tokens\", \"label_list\"]:\n",
    "    df_wnut[col] = df_wnut[col].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_wnut[\"tokens\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnut[\"tags\"] = df_wnut[\"label_list\"].apply(lambda x: [label_to_id[label] for label in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# reworked prediction function with max_length and error exceptions to handle cuda runtime error\n",
    "def bert_pred(model, tokenizer, df, text_col, output_col, max_length=128, batch_size=32):\n",
    "    device = model.device\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # printing model config info\n",
    "    if hasattr(model, 'config'):\n",
    "        print(f\"Model has {model.config.num_labels} labels\")\n",
    "\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            text = row[text_col]\n",
    "\n",
    "            if isinstance(text, np.ndarray):\n",
    "                if text.dtype.kind == 'U' or text.dtype.kind == 'S':\n",
    "                    text_list = text.tolist()\n",
    "                else:\n",
    "                    text_list = [str(x) for x in text]\n",
    "\n",
    "                if not text_list:\n",
    "                    all_predictions.append([])\n",
    "                    continue\n",
    "\n",
    "                encoded = tokenizer(\n",
    "                    text_list,\n",
    "                    is_split_into_words=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            elif isinstance(text, str):\n",
    "                if not text.strip():\n",
    "                    all_predictions.append([])\n",
    "                    continue\n",
    "\n",
    "                encoded = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            elif isinstance(text, list):\n",
    "                if not text:\n",
    "                    all_predictions.append([])\n",
    "                    continue\n",
    "\n",
    "                encoded = tokenizer(\n",
    "                    text,\n",
    "                    is_split_into_words=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            else:\n",
    "                encoded = tokenizer(\n",
    "                    str(text),\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "\n",
    "            encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "            if i == 0:\n",
    "                print(f\"Input shape: {encoded['input_ids'].shape}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**encoded)\n",
    "                preds = torch.argmax(outputs.logits, dim=-1)[0].cpu().tolist()\n",
    "\n",
    "                if isinstance(text, (list, np.ndarray)):\n",
    "                    if isinstance(text, np.ndarray):\n",
    "                        word_ids = tokenizer(\n",
    "                            text.tolist(),\n",
    "                            is_split_into_words=True,\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\"\n",
    "                        ).word_ids()\n",
    "                    else:\n",
    "                        word_ids = tokenizer(\n",
    "                            text,\n",
    "                            is_split_into_words=True,\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\"\n",
    "                        ).word_ids()\n",
    "\n",
    "                    processed_preds = []\n",
    "                    prev_word_id = None\n",
    "\n",
    "                    for word_id, pred in zip(word_ids, preds):\n",
    "                        if word_id is None:\n",
    "                            continue\n",
    "                        elif word_id != prev_word_id:\n",
    "                            processed_preds.append(pred)\n",
    "                        prev_word_id = word_id\n",
    "\n",
    "                    all_predictions.append(processed_preds)\n",
    "                else:\n",
    "                    all_predictions.append(preds)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in row {i}: {e}\")\n",
    "            # adding empty predictions for failed rows\n",
    "            all_predictions.append([])\n",
    "            continue\n",
    "\n",
    "    df[output_col] = all_predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(roberta_tweetner, roberta_tweetner_t, df_wnut, \"tokens\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(df_wnut, \"tags\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Finetuning RoBERTa-tweetner7 with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_syn = pd.read_csv(\"./NER_data/synthetic_tweet_data_grouped2.csv\")\n",
    "df_syn_sm = df_syn[:25000]\n",
    "df_syn_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_syn_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dict_syn = {\n",
    "    0: \"B-corporation\",\n",
    "    1: \"B-person\",\n",
    "    2: \"B-product\",\n",
    "    3: \"I-corporation\",\n",
    "    4: \"I-person\",\n",
    "    5: \"I-product\",\n",
    "    6: \"O\"\n",
    "}\n",
    "\n",
    "label_list = list(entity_dict_syn.values())\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "# def encode_labels(ds):\n",
    "#      ds['new_tags'] = [label_to_id[label] for label in ds['labels']]\n",
    "#      return ds\n",
    "\n",
    "# def encode_labels(ds):\n",
    "#     ds['new_tags'] = [\n",
    "#         [label_to_id[label] for label in labels] if isinstance(labels, list) else []\n",
    "#         for labels in ds['labels']\n",
    "#     ]\n",
    "#     return ds\n",
    "\n",
    "# train_dataset = train_dataset.map(encode_labels)\n",
    "# test_dataset = test_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = roberta_tweetner_t(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_id = None\n",
    "\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:\n",
    "                try:\n",
    "                    label_ids.append(label[word_id])\n",
    "                except IndexError:\n",
    "                    label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new syn data gen approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = [\n",
    "        \"John Smith\", \"Emily Chen\", \"Michael Johnson\", \"Sarah Williams\",\n",
    "        \"David Lee\", \"Maria Rodriguez\", \"James Brown\", \"Davis\",\n",
    "        \"Robert Kim\", \"Jennifer Lopez\", \"Thomas Wilson\", \"Jessica Taylor\", \"Cook\",\n",
    "        \"Carlos Vega\", \"Aisha Patel\", \"Daniel Park\", \"Olivia Nguyen\", \"Musk\", \"Smith\"\n",
    "    ]\n",
    "\n",
    "corporations = [\n",
    "        \"Google\", \"Microsoft\", \"Apple\", \"Amazon\", \"Meta\", \"BlackBerry\",\n",
    "        \"IBM\", \"Tesla\", \"Netflix\", \"Walmart\", \"JP Morgan\",\n",
    "        \"Acme Corp\", \"TechSolutions\", \"Global Systems\", \"DataWorks\",\n",
    "        \"Quantum Industries\", \"NexGen\", \"FutureSpace\", \"EcoSystems\", \"Nokia\", \"Motorola\"\n",
    "    ]\n",
    "\n",
    "products = [\n",
    "        \"iPhone 13\", \"Galaxy S22\", \"Surface Pro\", \"PlayStation 5\", \"Xbox Series X\",\n",
    "        \"MacBook Air\", \"Echo Dot\", \"AirPods Pro\", \"Tesla Model 3\", \"iPad Mini\",\n",
    "        \"Dyson V11\", \"Fitbit Charge\", \"Nintendo Switch\", \"Kindle Paperwhite\",\n",
    "        \"Roomba i7\", \"GoPro Hero\", \"Bose QuietComfort\", \"Instant Pot\", \"Echo\", \"AirTag\", \"ThinkPad\"\n",
    "    ]\n",
    "\n",
    "events = [\n",
    "        \"CES 2023\", \"Web Summit\", \"SXSW\", \"TechCrunch Disrupt\", \"E3 Expo\",\n",
    "        \"Google I/O\", \"WWDC\", \"Consumer Electronics Show\", \"Mobile World Congress\",\n",
    "        \"Black Hat Conference\", \"DEF CON\", \"AWS re:Invent\", \"Game Developers Conference\",\n",
    "        \"Dreamforce\", \"Comic-Con\", \"Coachella\", \"New York Fashion Week\", \"GamesCom\", \"AI-Con\"\n",
    "    ]\n",
    "\n",
    "locations = [\n",
    "        \"New York\", \"San Francisco\", \"London\", \"Tokyo\", \"Berlin\",\n",
    "        \"Paris\", \"Sydney\", \"Toronto\", \"Chicago\", \"Seattle\",\n",
    "        \"Los Angeles\", \"Miami\", \"Singapore\", \"Hong Kong\", \"Milwaukee\",\n",
    "        \"Dubai\", \"Barcelona\", \"Austin\", \"Stockholm\", \"Seoul\", \"Vienna\"\n",
    "    ]\n",
    "\n",
    "templates = [\n",
    "        \"{person} from {corporation} announced that {product} will be showcased at {event}.\",\n",
    "        \"At {event}, {person} demonstrated how {product} is revolutionizing {corporation}'s approach in {location}.\",\n",
    "        \"{corporation} has selected {location} as the venue for {event}, where {person} will launch {product}.\",\n",
    "        \"The new {product} developed by {corporation} will be presented by {person} during {event} in {location}.\",\n",
    "        \"{person} confirmed that {corporation} will be expanding its {product} line.\",\n",
    "        \"According to {person}, {corporation}'s latest {product} has been well-received at {event} in {location}.\",\n",
    "        \"Reviews from {event} suggest that {person} made a strong case for {corporation}'s new {product} in the {location} market.\",\n",
    "        \"{corporation} is planning to open a {product} store in {location}, announced {person} at {event}.\",\n",
    "        \"The collaboration between {corporation} and {person} resulted in {product}, which will finally debut at {event} in {location}.\",\n",
    "        \"Attendees at {event} in {location} were very impressed when {person} revealed {corporation}'s innovative {product}! The clapping didnt stop\",\n",
    "        \"{person} traveled to {location} to promote {product} at {event} on behalf of {corporation}.\",\n",
    "        \"The {product} team from {corporation}, led by {person}, won first prize at {event} in {location}. Let's go!\",\n",
    "        \"Consumers in {location} can now purchase {product} after {corporation}'s expansion announcement by {person} at {event}.\",\n",
    "        \"{product} is the must-have gadget of the year.\",\n",
    "        \"I hate the new {product}, the older ones are much better.\",\n",
    "        \"Less than 2 hours until they announce the details on the {product} giveaway!\",\n",
    "        \"All eyes are on {corporation} after the announcement of their new {product}.\",\n",
    "        \"It's time for {person} to leave {corporation}. What is he even doing.\",\n",
    "        \"{corporation} has been selected as the top AI startup in {location}, wow!\",\n",
    "        \"I am having so many issues with the {product}. {corporation} needs to fix this!\",\n",
    "        \"Can not wait for {product} also. They should sell them down at {event}.\",\n",
    "        \"Whats happening at {corporation}? {person} really needs to step up.\",\n",
    "        \"{corporation} is giving free {product} to open source coders who are attending this meet-up.\",\n",
    "        \"{person} was right! The {product} from {corporation} is revolutionary!\",\n",
    "        \"Less than 2 hours until we announce the details on the {product} giveaway!\",\n",
    "        \"{corporation} CEO {person}: Newest {product} rollout will begin next month!\",\n",
    "        \"{corporation} has a temporary Retail Store in {location} for the {product} release today. Opens at 5pm.\",\n",
    "        \"{person} said that {corporation} is working on something big.\",\n",
    "        \"It's time for {person} to leave {corporation}. What is he even doing?\",\n",
    "        \"{corporation} just keeps raising the bar with every {product} they launch. Crazy!\",\n",
    "        \"{person} just hinted at new features in {corporation}'s upcoming {product}. I am hyped!\",\n",
    "        \"Rumors say {corporation} is releasing {product} soon.\",\n",
    "        \"Just watched the {corporation} keynote. {product} looks impressive.\",\n",
    "        \"Is it just me, or does {corporation}'s {product} feel rushed and unfinished?\",\n",
    "        \"The {product} is making me rethink my loyalty to {corporation}. Its not good.\",\n",
    "        \"Who else is gonna get the new {product} next month?\",\n",
    "        \"{corporation}'s industry party tonight was great for the launch of {product}.\",\n",
    "        \"Attending {event} this week! Can't wait to see what {corporation} unveils about their upcoming {product}. Anyone else going?\",\n",
    "        \"Is anyone else experiencing issues with the new {product} update? {corporation}'s support hasn't been helpful. #TechSupport\",\n",
    "        \"Just switched from {product} to {product} and the difference is incredible. {corporation} really cooked with this one!\",\n",
    "        \"Hot take: {corporation}'s approach to development is outdated. They need to focus more on usability if they want to compete with {corporation}\",\n",
    "        \"The new update to {product} completely revolutionized my workflow. Thanks {corporation} for fixing the issue! #ProductivityTech\",\n",
    "        \"Arrived at {event} in {location}! The {corporation} booth is already packed with people trying the new {product}. #TechConference\",\n",
    "        \"Just spotted {person} from {corporation} at a restaurant in {location} right after {event}. Tried to ask about {product} rumors but no comment!\",\n",
    "        \"I snuck into the VIP section at {event} in {location} and got a selfie with {person}! Check my Insta! #Winning\",\n",
    "        \"PSA: Free {product} giveaways at {corporation}'s booth at {event} in {location}! Run don't walk, peeps! I got the last blue one\",\n",
    "        \"This {product} launch line at {corporation}'s store in {location} is ridiculous. Been here 3hrs and moved like 10 feet, But I NEED it today! #TechAddict\",\n",
    "        \"Shoutout to the nice {corporation} rep at {event} in {location} who gave me an extra {product} for my kid! Some tech people are actually decent humans\",\n",
    "        \"My {product} just updated itself and now I can't find ANYTHING. Hey {corporation}, stop 'fixing' stuff that ain't broken! {person} needs to chill with these changes\",\n",
    "        \"Omg {person} just liked my tweet criticizing {corporation}'s {product}! Screenshot this before they realize and unlike!\",\n",
    "        \"The way {person} casually uses {product} in interviews makes it seem so cool, but when I bought it from {corporation} it's just... meh. Marketing wins again\",\n",
    "        \"new CEO {person} has really not done much yet at {corporation}, hasnt he?\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# reworked new function\n",
    "def generate_ner_dataset(num_examples, templates=templates,persons=persons, corporations=corporations,\n",
    "                         products=products, events=events, locations=locations):\n",
    "    data = []\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        template = random.choice(templates)\n",
    "\n",
    "        person = random.choice(persons)\n",
    "        corporation = random.choice(corporations)\n",
    "        product = random.choice(products)\n",
    "        event = random.choice(events)\n",
    "        location = random.choice(locations)\n",
    "\n",
    "        sentence = template.format(\n",
    "            person=person,\n",
    "            corporation=corporation,\n",
    "            product=product,\n",
    "            event=event,\n",
    "            location=location\n",
    "        )\n",
    "\n",
    "        tokens = []\n",
    "        labels = []\n",
    "\n",
    "        raw_words = []\n",
    "        current_word = \"\"\n",
    "        for char in sentence:\n",
    "            if char.isalnum() or char in \"-'\":\n",
    "                current_word += char\n",
    "            else:\n",
    "                if current_word:\n",
    "                    raw_words.append(current_word)\n",
    "                    current_word = \"\"\n",
    "                if not char.isspace():\n",
    "                    raw_words.append(char)\n",
    "        if current_word:\n",
    "            raw_words.append(current_word)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(raw_words):\n",
    "            token = raw_words[i]\n",
    "\n",
    "            found_entity = False\n",
    "\n",
    "            if i < len(raw_words) - 1 and f\"{raw_words[i]} {raw_words[i+1]}\" in persons:\n",
    "                tokens.append(raw_words[i])\n",
    "                tokens.append(raw_words[i+1])\n",
    "                labels.append(\"B-person\")\n",
    "                labels.append(\"I-person\")\n",
    "                i += 2\n",
    "                found_entity = True\n",
    "\n",
    "            elif i < len(raw_words) - 2 and f\"{raw_words[i]} {raw_words[i+1]} {raw_words[i+2]}\" in products:\n",
    "                tokens.append(raw_words[i])\n",
    "                tokens.append(raw_words[i+1])\n",
    "                tokens.append(raw_words[i+2])\n",
    "                labels.append(\"B-product\")\n",
    "                labels.append(\"I-product\")\n",
    "                labels.append(\"I-product\")\n",
    "                i += 3\n",
    "                found_entity = True\n",
    "            elif i < len(raw_words) - 1 and f\"{raw_words[i]} {raw_words[i+1]}\" in products:\n",
    "                tokens.append(raw_words[i])\n",
    "                tokens.append(raw_words[i+1])\n",
    "                labels.append(\"B-product\")\n",
    "                labels.append(\"I-product\")\n",
    "                i += 2\n",
    "                found_entity = True\n",
    "\n",
    "            elif i < len(raw_words) - 2 and f\"{raw_words[i]} {raw_words[i+1]} {raw_words[i+2]}\" in events:\n",
    "                tokens.append(raw_words[i])\n",
    "                tokens.append(raw_words[i+1])\n",
    "                tokens.append(raw_words[i+2])\n",
    "                labels.append(\"B-event\")\n",
    "                labels.append(\"I-event\")\n",
    "                labels.append(\"I-event\")\n",
    "                i += 3\n",
    "                found_entity = True\n",
    "            elif i < len(raw_words) - 1 and f\"{raw_words[i]} {raw_words[i+1]}\" in events:\n",
    "                tokens.append(raw_words[i])\n",
    "                tokens.append(raw_words[i+1])\n",
    "                labels.append(\"B-event\")\n",
    "                labels.append(\"I-event\")\n",
    "                i += 2\n",
    "                found_entity = True\n",
    "\n",
    "            elif i < len(raw_words) - 1 and f\"{raw_words[i]} {raw_words[i+1]}\" in locations:\n",
    "                tokens.append(raw_words[i])\n",
    "                tokens.append(raw_words[i+1])\n",
    "                labels.append(\"B-location\")\n",
    "                labels.append(\"I-location\")\n",
    "                i += 2\n",
    "                found_entity = True\n",
    "\n",
    "            if not found_entity:\n",
    "                if token in [name.split()[0] for name in persons]:\n",
    "                    tokens.append(token)\n",
    "                    labels.append(\"B-person\")\n",
    "                    i += 1\n",
    "                elif token in corporations:\n",
    "                    tokens.append(token)\n",
    "                    labels.append(\"B-corporation\")\n",
    "                    i += 1\n",
    "                elif token in products:\n",
    "                    tokens.append(token)\n",
    "                    labels.append(\"B-product\")\n",
    "                    i += 1\n",
    "                elif token in events:\n",
    "                    tokens.append(token)\n",
    "                    labels.append(\"B-event\")\n",
    "                    i += 1\n",
    "                elif token in locations:\n",
    "                    tokens.append(token)\n",
    "                    labels.append(\"B-location\")\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tokens.append(token)\n",
    "                    labels.append(\"O\")\n",
    "                    i += 1\n",
    "\n",
    "        data.append({\"tokens\": tokens, \"labels\": labels, \"sentence\": sentence})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_new3 = generate_ner_dataset(10000)\n",
    "df_syn_new3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting named-tags to numeric tags for comparison with model output\n",
    "def convert_to_numeric(label_list):\n",
    "    return [label_to_id.get(label, -100) for label in label_list]\n",
    "\n",
    "df_syn_new3[\"tags\"] = df_syn_new3[\"labels\"].apply(convert_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predicting with RoBERTa-TweetNER7 on syn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(roberta_tweetner, roberta_tweetner_t, df_syn_new3, \"tokens\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn_new3[\"roberta_pred_labels\"] = df_syn_new3[\"roberta_pred\"].apply(tags_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "true = df_syn_new3[\"labels\"].values.tolist()\n",
    "pred = df_syn_new3[\"roberta_pred_labels\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"creative_work\", \"event\", \"group\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_ner_predictions(df_syn_new3, \"tags\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset_syn = Dataset.from_pandas(df_syn_new3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset_syn.train_test_split(test_size=0.2)\n",
    "train_dataset_syn = train_test_split['train']\n",
    "test_dataset_syn = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {tag: id for id, tag in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works with synthetic data from above\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = roberta_tweetner_t(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:\n",
    "                if isinstance(label[word_id], str):\n",
    "                    # converting string label to id\n",
    "                    label_ids.append(label_map[label[word_id]])\n",
    "                else:\n",
    "                    label_ids.append(label[word_id])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_syn = train_dataset_syn.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset_syn = test_dataset_syn.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # flattening predictions and labels\n",
    "    true_labels = [id_to_label[label] for label in labels.flatten() if label != -100]\n",
    "    true_predictions = [id_to_label[pred] for (pred, label) in zip(predictions.flatten(), labels.flatten()) if label != -100]\n",
    "\n",
    "    # calculating metrics\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta-tweetner-syndata\",\n",
    "    evaluation_strategy=\"epoch\",   # evaluating at every epoch\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=64, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=roberta_tweetner,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_syn,\n",
    "    eval_dataset=test_dataset_syn,\n",
    "    tokenizer=roberta_tweetner_t,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning RoBERTa-base with corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "roberta_t = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\", add_prefix_space=True)\n",
    "\n",
    "entity_dict = {\n",
    "    0: \"B-corporation\",\n",
    "    1: \"B-event\",\n",
    "    2: \"B-location\",\n",
    "    3: \"B-person\",\n",
    "    4: \"B-product\",\n",
    "    5: \"I-corporation\",\n",
    "    6: \"I-event\",\n",
    "    7: \"I-location\",\n",
    "    8: \"I-person\",\n",
    "    9: \"I-product\",\n",
    "    10: \"O\"\n",
    "}\n",
    "\n",
    "label_list = list(entity_dict.values())\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "roberta = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"FacebookAI/roberta-base\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_corpus = pd.read_json(\"NER_corpus.json\", orient=\"records\")\n",
    "df_corpus.rename(columns={\"labels\":\"original_labels\"}, inplace=True)\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df_corpus)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = roberta_t(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:  # Special tokens\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:  # First token of a word\n",
    "                label_ids.append(label[word_id])\n",
    "            else:  # Subword tokens\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split1 = tokenized_datasets.train_test_split(test_size=0.15, seed=42)\n",
    "train_val_dataset = train_test_split1[\"train\"]\n",
    "test_dataset = train_test_split1[\"test\"]\n",
    "\n",
    "train_test_split2 = train_val_dataset.train_test_split(test_size=0.15, seed=42)\n",
    "train_dataset = train_test_split2[\"train\"]\n",
    "val_dataset = train_test_split2[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # flattening predictions and labels\n",
    "    true_labels = [id_to_label[label] for label in labels.flatten() if label != -100]\n",
    "    true_predictions = [id_to_label[pred] for (pred, label) in zip(predictions.flatten(), labels.flatten()) if label != -100]\n",
    "\n",
    "    # calculating metrics\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-roberta-base\",\n",
    "    evaluation_strategy=\"epoch\", # evaluating at every epoch\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=roberta,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=roberta_t,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./roberta-base-after-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "roberta_corpus_t = AutoTokenizer.from_pretrained(\"./roberta-base-after-corpus\")\n",
    "roberta_corpus = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"./roberta-base-after-corpus\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_test = test_dataset.to_pandas()\n",
    "df_corpus_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(roberta_corpus, roberta_corpus_t, df_corpus_test, \"tokens\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "df_corpus_test[\"pred_labels\"] = df_corpus_test[\"roberta_pred\"].apply(lambda x: [id_to_label[i] for i in x])\n",
    "\n",
    "true = df_corpus_test[\"original_labels\"].values.tolist()\n",
    "pred = df_corpus_test[\"pred_labels\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"event\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(df_corpus_test, \"tags\", \"roberta_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning covid twitter bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with TweetNER7-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the covid-twitter-bert model, since most other bert-based models\n",
    "# have already been fine-tuned on this data with most likely better resources\n",
    "# https://huggingface.co/datasets/tner/tweetner7#main-models\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "model_name_covid = \"digitalepidemiologylab/covid-twitter-bert-v2\"\n",
    "tokenizer_covid = AutoTokenizer.from_pretrained(model_name_covid)\n",
    "\n",
    "#model_covid = AutoModelForTokenClassification.from_pretrained(model_name_covid)\n",
    "#ner_pipeline_covid = pipeline(\"ner\", model=model_covid, tokenizer=tokenizer_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(tweetner7_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"true_labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = list(entity_dict.values())\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "def encode_labels(ds):\n",
    "    ds['new_tags'] = [label_to_id[label] for label in ds['true_labels']]\n",
    "    return ds\n",
    "\n",
    "train_dataset = train_dataset.map(encode_labels)\n",
    "test_dataset = test_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer_covid(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"new_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:  # Special tokens\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:  # First token of a word\n",
    "                label_ids.append(label[word_id])\n",
    "            else:  # Subword tokens\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model_covid = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name_covid,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "# using a data collator for dynamic padding to solve error during tensor creation\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # flattening predictions and labels\n",
    "    true_labels = [id_to_label[label] for label in labels.flatten() if label != -100]\n",
    "    true_predictions = [id_to_label[pred] for (pred, label) in zip(predictions.flatten(), labels.flatten()) if label != -100]\n",
    "\n",
    "    # calculating metrics\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-covid-twitter-bert\",\n",
    "    evaluation_strategy=\"epoch\",   # evaluating at every epoch\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_covid,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer_covid,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the fine-tuned model\n",
    "model_covid.save_pretrained(\"./models/ner-covid-twitter-bert_after_first_finetuning\")\n",
    "tokenizer_covid.save_pretrained(\"./models/ner-covid-twitter-bert_after_first_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model and applying it\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer_covid_f = AutoTokenizer.from_pretrained(\"./models/ner-covid-twitter-bert_after_first_finetuning\")\n",
    "model_covid_f = AutoModelForTokenClassification.from_pretrained(\"./models/ner-covid-twitter-bert_after_first_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fine_tuned_model_path = \"./models/covid-twitter-bert_after_first_finetuning\"\n",
    "pipeline_covid_f = pipeline(\"ner\", model=fine_tuned_model_path, tokenizer=fine_tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_big[\"pred_covidtwitterbert_f\"] = tweetner7_big.apply(lambda x: pipeline_covid_f(str(x[\"tokens\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_big[\"pred_labels_covidtwitterbert_f\"] = tweetner7_big.apply(output_to_labellist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "true = tweetner7_big[\"true_labels\"].values.tolist()\n",
    "pred = tweetner7_big[\"pred_labels_covidtwitterbert_f\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"creative_work\", \"event\", \"group\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_tag[\"product\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with NER-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_covid = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "entity_dict = {\n",
    "    0: \"B-corporation\",\n",
    "    1: \"B-event\",\n",
    "    2: \"B-location\",\n",
    "    3: \"B-person\",\n",
    "    4: \"B-product\",\n",
    "    5: \"I-corporation\",\n",
    "    6: \"I-event\",\n",
    "    7: \"I-location\",\n",
    "    8: \"I-person\",\n",
    "    9: \"I-product\",\n",
    "    10: \"O\"\n",
    "}\n",
    "\n",
    "label_list = list(entity_dict.values())\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "model_covid = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"digitalepidemiologylab/covid-twitter-bert-v2\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_corpus = pd.read_json(\"NER_corpus.json\", orient=\"records\")\n",
    "df_corpus.rename(columns={\"labels\":\"original_labels\"}, inplace=True)\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df_corpus)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer_covid(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:  # Special tokens\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:  # First token of a word\n",
    "                label_ids.append(label[word_id])\n",
    "            else:  # Subword tokens\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split1 = tokenized_datasets.train_test_split(test_size=0.15, seed=42)\n",
    "train_val_dataset = train_test_split1[\"train\"]\n",
    "test_dataset = train_test_split1[\"test\"]\n",
    "\n",
    "train_test_split2 = train_val_dataset.train_test_split(test_size=0.15, seed=42)\n",
    "train_dataset = train_test_split2[\"train\"]\n",
    "val_dataset = train_test_split2[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # flattening predictions and labels\n",
    "    true_labels = [id_to_label[label] for label in labels.flatten() if label != -100]\n",
    "    true_predictions = [id_to_label[pred] for (pred, label) in zip(predictions.flatten(), labels.flatten()) if label != -100]\n",
    "\n",
    "    # calculating metrics\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-covid-twitter-bert\",\n",
    "    evaluation_strategy=\"epoch\", # evaluating at every epoch\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_covid,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer_covid,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./ner-covid-twitter-bert_after_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "bert_covid_corpus_t = AutoTokenizer.from_pretrained(\"./ner-covid-twitter-bert_after_corpus\")\n",
    "bert_covid_corpus = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"./ner-covid-twitter-bert_after_corpus\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test_df = test_dataset.to_pandas()\n",
    "corpus_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "param_device = next(bert_covid_corpus.parameters()).device\n",
    "\n",
    "# prediction function with max_length and error exceptions to handle cuda runtime error but predicting on GPU\n",
    "def bert_pred(model, tokenizer, df, text_col, output_col, max_length=128, batch_size=32):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    #device = model.device\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # printing model config info\n",
    "    if hasattr(model, 'config'):\n",
    "        print(f\"Model has {model.config.num_labels} labels\")\n",
    "\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            text = row[text_col]\n",
    "\n",
    "            if isinstance(text, np.ndarray):\n",
    "                if text.dtype.kind == 'U' or text.dtype.kind == 'S':\n",
    "                    text_list = text.tolist()\n",
    "                else:\n",
    "                    text_list = [str(x) for x in text]\n",
    "\n",
    "                if not text_list:\n",
    "                    all_predictions.append([])\n",
    "                    continue\n",
    "\n",
    "                encoded = tokenizer(\n",
    "                    text_list,\n",
    "                    is_split_into_words=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            elif isinstance(text, str):\n",
    "                if not text.strip():\n",
    "                    all_predictions.append([])\n",
    "                    continue\n",
    "\n",
    "                encoded = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            elif isinstance(text, list):\n",
    "                if not text:\n",
    "                    all_predictions.append([])\n",
    "                    continue\n",
    "\n",
    "                encoded = tokenizer(\n",
    "                    text,\n",
    "                    is_split_into_words=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            else:\n",
    "                encoded = tokenizer(\n",
    "                    str(text),\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=max_length,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "\n",
    "            encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "            if i == 0:\n",
    "                print(f\"Input shape: {encoded['input_ids'].shape}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**encoded)\n",
    "                preds = torch.argmax(outputs.logits, dim=-1)[0].cpu().tolist()\n",
    "\n",
    "                if isinstance(text, (list, np.ndarray)):\n",
    "                    if isinstance(text, np.ndarray):\n",
    "                        word_ids = tokenizer(\n",
    "                            text.tolist(),\n",
    "                            is_split_into_words=True,\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\"\n",
    "                        ).word_ids()\n",
    "                    else:\n",
    "                        word_ids = tokenizer(\n",
    "                            text,\n",
    "                            is_split_into_words=True,\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\"\n",
    "                        ).word_ids()\n",
    "\n",
    "                    processed_preds = []\n",
    "                    prev_word_id = None\n",
    "\n",
    "                    for word_id, pred in zip(word_ids, preds):\n",
    "                        if word_id is None:\n",
    "                            continue\n",
    "                        elif word_id != prev_word_id:\n",
    "                            processed_preds.append(pred)\n",
    "                        prev_word_id = word_id\n",
    "\n",
    "                    all_predictions.append(processed_preds)\n",
    "                else:\n",
    "                    all_predictions.append(preds)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in row {i}: {e}\")\n",
    "            # adding empty predictions for failed rows\n",
    "            all_predictions.append([])\n",
    "            continue\n",
    "\n",
    "    df[output_col] = all_predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(bert_covid_corpus, bert_covid_corpus_t, corpus_test_df, \"tokens\", \"covid_bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test_df[\"covid_bert_pred\"].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "corpus_test_df[\"pred_labels\"] = corpus_test_df[\"covid_bert_pred\"].apply(lambda x: [id_to_label[i] for i in x])\n",
    "\n",
    "true = corpus_test_df[\"original_labels\"].values.tolist()\n",
    "pred = corpus_test_df[\"pred_labels\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"event\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(corpus_test_df, \"tags\", \"covid_bert_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying model to case study data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dell = pd.read_json(\"dell_cs_processed.json\", orient=\"records\")\n",
    "df_dell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(bert_covid_corpus, bert_covid_corpus_t, df_dell, \"tokens\", \"covid_bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dell.to_json(\"dell_cs_after_ner.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine-tuning BERT-base with tweetner7-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "#using cased BERT for NER because it may be advantageous (e.g. for persons, companies)\n",
    "# google-bert/bert-base-cased\n",
    "bert_base_cased_t = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "bert_base_cased = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-cased\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps between executed from loading and applying and syn data sections (until train- and test-dataset)\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = bert_base_cased_t(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]): # or \"new_tags\"\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:  # Special tokens\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:  # First token of a word\n",
    "                label_ids.append(label[word_id])\n",
    "            else:  # Subword tokens\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # flattening predictions and labels\n",
    "    true_labels = [id_to_label[label] for label in labels.flatten() if label != -100]\n",
    "    true_predictions = [id_to_label[pred] for (pred, label) in zip(predictions.flatten(), labels.flatten()) if label != -100]\n",
    "\n",
    "    # calculating metrics\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-bert-base-cased\",\n",
    "    evaluation_strategy=\"epoch\",   # evaluating at every epoch\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_base_cased,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=bert_base_cased_t,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_cased.save_pretrained(\"bert-base-cased-ner-tweetner7\")\n",
    "bert_base_cased_t.save_pretrained(\"bert-base-cased-ner-tweetner7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_c_ft_t = AutoTokenizer.from_pretrained(\"bert-base-cased-ner-tweetner7\")\n",
    "\n",
    "bert_c_ft = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased-ner-tweetner7\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(bert_c_ft, bert_c_ft_t, tweetner7_test20, \"tokens\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(tweetner7_test20, \"tags\", \"bert_pred\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd fine-tuning with tweetner7-bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetner7_validation20 = ds[\"validation_2020\"].to_pandas()\n",
    "tweetner7_validation21 = ds[\"validation_2021\"].to_pandas()\n",
    "\n",
    "# leaving \"test_2020\"-part out of training data to test\n",
    "tweetner7_test20 = ds[\"test_2020\"].to_pandas()\n",
    "\n",
    "tweetner7_bigger = pd.concat([tweetner7_big, tweetner7_validation20, tweetner7_validation21, tweetner7_test20])\n",
    "tweetner7_bigger.reset_index(drop=True, inplace=True)\n",
    "tweetner7_bigger.dropna(inplace=True)\n",
    "\n",
    "#tweetner7_test20.reset_index(drop=True, inplace=True)\n",
    "#tweetner7_test20.dropna(inplace=True)\n",
    "\n",
    "len(tweetner7_bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "#train_dataset_bigger = Dataset.from_pandas(tweetner7_bigger)\n",
    "#test_dataset_bigger = Dataset.from_pandas(tweetner7_test20)\n",
    "\n",
    "dataset = Dataset.from_pandas(tweetner7_bigger)\n",
    "\n",
    "# setting seed so that validation set is deterministic\n",
    "train_test_split = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "train_dataset_bigger = train_test_split['train']\n",
    "test_dataset_bigger = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_bigger = train_dataset_bigger.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset_bigger = test_dataset_bigger.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner-bert-base-cased\",\n",
    "    evaluation_strategy=\"epoch\",   # evaluating at every epoch\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=64, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_base_cased,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_bigger,\n",
    "    eval_dataset=test_dataset_bigger,\n",
    "    tokenizer=bert_base_cased_t,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_cased.save_pretrained(\"bert-base-cased-ner-tweetner7-bigger\")\n",
    "bert_base_cased_t.save_pretrained(\"bert-base-cased-ner-tweetner7-bigger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_c_ft_bigger_t = AutoTokenizer.from_pretrained(\"bert-base-cased-ner-tweetner7-bigger\")\n",
    "\n",
    "bert_c_ft_bigger = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased-ner-tweetner7-bigger\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_bigger_df = test_dataset_bigger.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(bert_c_ft_bigger, bert_c_ft_bigger_t, test_dataset_bigger_df, \"tokens\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(test_dataset_bigger_df, \"tags\", \"bert_pred\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying model on unlabeled data and analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on already processed Tweets-Bigtech-data\n",
    "df_bigtech = pd.read_csv(\"tweets_bigtech_10ksample.csv\")\n",
    "df_bigtech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtech_sm = df_bigtech.sample(n=1000, random_state=42)\n",
    "df_bigtech_sm.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtech_sm[\"tokens\"] = df_bigtech_sm.apply(lambda x: x[\"text\"].split(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(bert_c_ft_bigger, bert_c_ft_bigger_t, df_bigtech_sm, \"tokens\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtech_sm[\"pred_labels\"] = df_bigtech_sm[\"bert_pred\"].apply(tags_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtech_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_bigtech_sm[900:].iterrows():\n",
    "    print(row[1][\"text\"])\n",
    "    print(row[1][\"pred_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine-tuning BERT-base with NER-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# reduced entity dict fitting the corpus\n",
    "entity_dict_sm = {\n",
    "    0: \"B-corporation\",\n",
    "    1: \"B-event\",\n",
    "    2: \"B-location\",\n",
    "    3: \"B-person\",\n",
    "    4: \"B-product\",\n",
    "    5: \"I-corporation\",\n",
    "    6: \"I-event\",\n",
    "    7: \"I-location\",\n",
    "    8: \"I-person\",\n",
    "    9: \"I-product\",\n",
    "    10: \"O\"\n",
    "}\n",
    "\n",
    "label_list = list(entity_dict_sm.values())\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "\n",
    "bert_base_cased_t = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "bert_base_cased = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-cased\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_nerc = pd.read_json(\"NER_corpus.json\", orient=\"records\")\n",
    "df_nerc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_nerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_map = {tag: id for id, tag in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version of function that worked with synthetic data\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = bert_base_cased_t(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != previous_word_id:\n",
    "                if isinstance(label[word_id], str):\n",
    "                    # converting string label to id\n",
    "                    label_ids.append(label_map[label[word_id]])\n",
    "                else:\n",
    "                    label_ids.append(label[word_id])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_id = word_id\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split1 = tokenized_dataset.train_test_split(test_size=0.15, seed=42)\n",
    "train_val_dataset = train_test_split1['train']\n",
    "test_dataset = train_test_split1['test']\n",
    "\n",
    "train_test_split2 = train_val_dataset.train_test_split(test_size=0.15, seed=42)\n",
    "train_dataset = train_test_split2['train']\n",
    "val_dataset = train_test_split2['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # flattening predictions and labels\n",
    "    true_labels = [id_to_label[label] for label in labels.flatten() if label != -100]\n",
    "    true_predictions = [id_to_label[pred] for (pred, label) in zip(predictions.flatten(), labels.flatten()) if label != -100]\n",
    "\n",
    "    # calculating metrics\n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-base-cased-ner-corpus\",\n",
    "    evaluation_strategy=\"epoch\",   # evaluating at every epoch\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32, # adjust batch size depending on RAM\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_base_cased,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=bert_base_cased_t,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_cased.save_pretrained(\"./bert-base-cased-ner-corpus\")\n",
    "bert_base_cased_t.save_pretrained(\"./bert-base-cased-ner-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "bert_corpus_t = AutoTokenizer.from_pretrained(\"./bert-base-cased-ner-corpus\")\n",
    "\n",
    "bert_corpus = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"./bert-base-cased-ner-corpus\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_test = test_dataset.to_pandas()\n",
    "df_corpus_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_test[\"true_labels\"] = df_corpus_test[\"tags\"].apply(lambda x: [id_to_label[tag] for tag in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version of function from WNUT data\n",
    "bert_pred(bert_corpus, bert_corpus_t, df_corpus_test, \"tokens\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nervaluate import Evaluator\n",
    "\n",
    "df_corpus_test[\"bert_pred_labels\"] = df_corpus_test[\"bert_pred\"].apply(lambda x: [id_to_label[i] for i in x])\n",
    "\n",
    "true = df_corpus_test[\"true_labels\"].values.tolist()\n",
    "pred = df_corpus_test[\"bert_pred_labels\"].values.tolist()\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=[\"corporation\", \"event\", \"location\", \"person\", \"product\"], loader=\"list\")\n",
    "\n",
    "results, results_by_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_ner_predictions(df_corpus_test, \"tags\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tbt_app = pd.read_json(\"tweets_bigtech_10k_application.json\", orient=\"records\")\n",
    "df_tbt_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying model to unlabeled data for 2nd run through visualizations\n",
    "bert_pred(bert_corpus, bert_corpus_t, df_tbt_app, \"tokens\", \"bert_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tbt_app.to_json(\"tweets_bigtech_10k_application_afterNER.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_bigtech_sm[:100].iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"bert_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying model to dell data to create time plot\n",
    "df_dell = pd.read_json(\"sentiment_dell_processed.json\", orient=\"records\")\n",
    "df_dell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred(bert_corpus, bert_corpus_t, df_dell, \"tokens\", \"ner_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dell[\"ner_labels\"] = df_dell[\"ner_tags\"].apply(lambda x: [id_to_label[tag] for tag in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dell.to_json(\"dell_afterNER.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
